---
author: "Antonin"
date: "2016-04-01T01:39:20-04:00"
description: "Ghost in the shell..."
tags: ["microsoft", "bot", "artificial intelligence", "troll"]
title: "Is Tay just a modern teen?"
toc: false
readTime: true
---

![](/images/is_tay_just_a_modern_teen.jpeg#small)

## Abstract

[Tay](https://www.tay.ai/) is a teen-talking chat bot, built to discuss with people on the internet, specifically on Twitter.
This bot is a creation of Microsoft's Technology & Research and Bing teams, and was released eight days ago.
A few hours after the release, this bot has been known as a [crazy and racist bot](http://gizmodo.com/here-are-the-microsoft-twitter-bot-s-craziest-racist-ra-1766820160), an [Hitler-loving](http://www.techrepublic.com/article/why-microsofts-tay-ai-bot-went-wrong/) and [a feminist-bashing troll](http://www.techrepublic.com/article/why-microsofts-tay-ai-bot-went-wrong/).
Tay [is now off](https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/#sm.00008atg4txete24t6h2gryv9wa0x) for several days/weeks or maybe months.

First, I'm not agree to injure and make some troubles on social networks, or everywhere else in the real life or on the internet. Also, to see a technology just says some horrible things makes me really sad.
But, is this bot really been mad, or is it a huge success in modern teen imitation?

## Let's talk about machine learning

Today, modern artificial intelligence applications are using two famous machine learning techniques: [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning) and [artificial neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network).
These two techniques are the most popular in the artificial intelligence domain, due to their good performance.
Also, they can be paired up, like the [AlphaGo algorithm](https://deepmind.com/alpha-go.html).

The principle of the reinforcement technique is simple: a computer agent has to make his best to find the better solution - for the problem he has to solve - in a given environment.
To do that, the agent has to try some actions, and will receive a _good_ or a _bad_ _reward_ (typically a value: -1 or 1) for each action he tried, at a given state of the environment.
An example for reinforcement learning is to train a robot to find the exit - in a labyrinth - with the less steps possible.

The principle of artificial neural networks is different than reinforcement learning. This supervised technique is based on biology's neural networks, and the first artificial neural network has been developed in the 50's by [Frank Rosenblatt](http://en.wikipedia.org/wiki/Frank_Rosenblatt), with [the perceptron model](https://en.wikipedia.org/wiki/Perceptron).
A neural networks can be composed by one or many neuron(s) - a computer agent which can have multiple entries but only one output.
Each entries have a weight.
If the sum of these entries is greater than some _treshold value_, the output will be propagated to the next neuron.
Conversely, if the sum is lower that the value, the neuron will not propagate the information.
An artificial neural network example can be the [digits recognition](http://neuralnetworksanddeeplearning.com/chap1.html).
Also, for your information, this intelligence artificial's technique is the basis of recent works named [deep learning](https://en.wikipedia.org/wiki/Deep_learning).

Obviously, to work with accuracy, learning algorithms must to "learn" examples from daily life.
**Real** examples, that you can found **in the nature**.

Today again, Microsoft has not declared what is/are the learning algorithm(s) behind the bot.
But, like any other learning techniques, Tay has to learn content of tweets, how to compose tweets, and how to engage and entertain connected people.
This learning exercise is made offline and online.
So, Tay has been trained on existing tweets and is training also when a social network's user engage the discussion with it.

## Tay's adaptation

Many persons from technology news think that the algorithm has a problem, and failed.
Microsoft search team, in a [post](https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/#sm.00008atg4txete24t6h2gryv9wa0x), confirms.
Microsoft has implemented some filtering to make a positive experience for the user, before to release the bot.
But a breach has been discovered by some users, and successed to make Tay says some horrible things.

To me, this part of the project is a fail, but not the goal of the project.
This project is just another artificial intelligence success.
Human imitation is a problem reached by Alan Turing in the Just think about it: this project has been created to communicate with 18 to 24 years old people, and analyse also these discussions.
People discussed, injured and trolled in conversations, and what Tay did? Exactly the same thing.
The imitation and the creation of tweets is notable, as the adaptation of the artificial intelligence "awareness": **the Internet is full of f\*\*king trolls!**

So, do you think (too) I can now replace my "it" statements with "her"...?

_Cover picture from [ubergizmo.com](http://ubergizmo.com)._
